{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "key_word_model1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreasfloros/ARM-ML-Embedded/blob/main/audio_classifier_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDKVJZ0SnY8z"
      },
      "source": [
        "# Audio classifier pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhjmJcqIe4Ku"
      },
      "source": [
        "### 1) Download and untar dataset directly to colab:\n",
        "\n",
        "To change between datasets change the url to one which downloads a .tar file.\n",
        "\n",
        "**Note 1: If the audio_data folder already exists in your collab session running the following cell will give an error. That is not a problem, run it anyway.**\n",
        "\n",
        "**Note 2: For the Speech Commands dataset you MUST delete the README.md file in the audio_data/background_noise subfolder. This is the only file not in .wav format in the entire directory and since .md files cannot be read by the audio processing library not deleting it will cause the algorithms to fail when processing the dataset!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hROJGZ_rWPGa"
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "DATASET_ROOT_DIR = 'audio_data/'\n",
        "os.mkdir(DATASET_ROOT_DIR)\n",
        "url = 'http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz'\n",
        "target_path = 'audio_data/dataset.tar.gz'\n",
        "\n",
        "response = requests.get(url, stream=True)\n",
        "if response.status_code == 200:\n",
        "    with open(target_path, 'wb') as f:\n",
        "        f.write(response.raw.read())\n",
        "\n",
        "tar = tarfile.open(target_path, \"r:gz\")\n",
        "tar.extractall(path='audio_data/')\n",
        "tar.close()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_mTATcwlAle"
      },
      "source": [
        "### 2) Preprocess dataset:\n",
        "\n",
        "We iterate through the entire dataset, process every audio track using a processing method (either FFT, STFT, or MFCC), and store all of them in a JSON file. Currently, the user is able to control the processing method, expected duration of the audio tracks, the sample rate, as well as other values related to the processing methods.\n",
        "\n",
        "Potentially, the user might also be able (in the future) to automatically go through all processing methods and use the one which optimizes the current model accuracy.\n",
        "\n",
        "The process explained above can be completed through the following steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-hzEODswh24"
      },
      "source": [
        "**Step 1:** Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q868TWmywSTW"
      },
      "source": [
        "import os\n",
        "import librosa\n",
        "import math\n",
        "import json\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jsjd9sGwsbw"
      },
      "source": [
        "**Step 2:** Function to extend/cut tracks appropriately so that all contain the expected number of samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExNJOdGAwUS3"
      },
      "source": [
        "def make_track_correct_size(signal, expected_num_samples_per_track):\n",
        "\n",
        "    # print('Original track length: {}'.format(len(signal)))\n",
        "    # if track is shorter than expected, append it with zeros\n",
        "    if len(signal) < expected_num_samples_per_track:\n",
        "      num_zeros_to_pad = expected_num_samples_per_track - len(signal)\n",
        "      zeros = num_zeros_to_pad * [0.]\n",
        "      extended_signal = np.append(signal, zeros)\n",
        "      return extended_signal\n",
        "\n",
        "    # if track is longer than expected, truncate it\n",
        "    elif len(signal) > expected_num_samples_per_track:\n",
        "      return signal[:expected_num_samples_per_track]\n",
        "\n",
        "    # else return the original track \n",
        "    else:\n",
        "      return signal"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5KBOt9mw9o-"
      },
      "source": [
        "**Step 3:** Define function to process a single track using the method specified as input and return the data structure containing the result. This function will be called for all tracks within the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ndxpmhtwYhw"
      },
      "source": [
        "def audio_track_to_features(signal, processing_method, sample_rate, window_size, window_stride, num_mfcc):\n",
        "\n",
        "  if processing_method == 'fft':\n",
        "    # perform Fast Fourier Transform (FFT)\n",
        "    fft = np.fft.fft(signal)\n",
        "\n",
        "    # calculate abs values on complex numbers to get magnitude\n",
        "    spectrum = np.abs(fft)\n",
        "\n",
        "    # the spectrum is symmetrical with respect to sample_rate / 2\n",
        "    # so take half of the spectrum and frequency arrays\n",
        "    # therefore len(half_spectrum) = sample_rate / 2\n",
        "    half_spectrum = spectrum[:int(len(spectrum)/2)]\n",
        "\n",
        "    # average every 10 samples to reduce size of array to 1 / 10 of its original size\n",
        "    averaged = np.mean(half_spectrum.reshape(-1, 20), axis=1)\n",
        "\n",
        "    # convert to a 2D shape to fit the neural network's Conv2D layer input shape specs\n",
        "    two_dimentional = np.reshape(averaged, (1, len(averaged)))\n",
        "    return two_dimentional\n",
        "\n",
        "\n",
        "  elif processing_method == 'stft':\n",
        "    # perform Short Time Fourier Transform (STFT)\n",
        "    stft = librosa.stft(signal, n_fft=window_size, hop_length=window_stride)\n",
        "\n",
        "    # calculate abs values on complex numbers to get magnitude\n",
        "    spectrogram = np.abs(stft)\n",
        "\n",
        "    # transpose and return the spectrogram matrix\n",
        "    transposed_spectrogram = spectrogram.transpose()\n",
        "    return transposed_spectrogram\n",
        "\n",
        "\n",
        "  else: # mfcc\n",
        "    # perform Mel-Frequency Cepstral Coefficients (MFCC)\n",
        "    mfcc = librosa.feature.mfcc(signal, \n",
        "                                sr = sample_rate, \n",
        "                                n_fft = window_size, \n",
        "                                n_mfcc = num_mfcc,\n",
        "                                hop_length = window_stride)\n",
        "    # transpose and return the mfcc matrix\n",
        "    transposed_mfcc = mfcc.T\n",
        "    return transposed_mfcc"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcI71k9s1tg2"
      },
      "source": [
        "**Step 4:** Define function to process every audio track and create a JSON file with the entire processed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBwlSAsbfyKi"
      },
      "source": [
        "def preprocess_entire_dataset(dataset_path, json_path, processing_method, sample_rate, expected_duration, window_size, window_stride, num_mfcc):\n",
        "  # expected duration is in seconds\n",
        "  expected_num_samples_per_track = expected_duration * sample_rate\n",
        "  \n",
        "  # dictionary to later be converted to final json file\n",
        "  data = {\n",
        "      'mapping' : [],\n",
        "      'features' : [],\n",
        "      'labels' : []\n",
        "  }\n",
        "\n",
        "  # iterate through all subfolders\n",
        "  for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "    # # ensure we are not at the dataset root directory\n",
        "    # # (os.walk provides this directory as well)\n",
        "    if dirpath is not DATASET_ROOT_DIR:\n",
        "\n",
        "      # obtain word labels\n",
        "      dirpath_components = dirpath.split('/') # audio_data/left => ['audio_data', 'left']\n",
        "      word_label = dirpath_components[-1]\n",
        "      data['mapping'].append(word_label)\n",
        "      print('Processing {}'.format(word_label))\n",
        "\n",
        "      # access and process files for current word\n",
        "      for f in filenames:\n",
        "        \n",
        "        # load audio file\n",
        "        file_path = os.path.join(dirpath, f)\n",
        "        signal, sample_rate = librosa.load(file_path, sr=sample_rate)\n",
        "\n",
        "        # extend or cut signal to be equal to the expected size\n",
        "        signal_correct_size = make_track_correct_size(signal, expected_num_samples_per_track)\n",
        "\n",
        "        # obtain the features of the audio track using the function defined above\n",
        "        track_features = audio_track_to_features(signal = signal_correct_size, \n",
        "                                                 processing_method = 'fft', \n",
        "                                                 sample_rate = sample_rate, \n",
        "                                                 window_size = window_size, \n",
        "                                                 window_stride = window_stride, \n",
        "                                                 num_mfcc = 13)\n",
        "        \n",
        "        # append the audio track features to the features field of the dictionary\n",
        "        data['features'].append(track_features.tolist())\n",
        "\n",
        "        # append the current index-1 as the label of this track\n",
        "        # the -1 comes from the fact that the index 0 refers to the dataset root directory,\n",
        "        # the only directory which does not have a label\n",
        "        data['labels'].append(i-1)\n",
        "        # print('file_path: {}'.format(file_path))\n",
        "\n",
        "\n",
        "  # create the json file from the dictionary\n",
        "  with open(json_path, 'w') as fp:\n",
        "    json.dump(data, fp, indent=4)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kApAU17Yk2rS"
      },
      "source": [
        "**Step 5:** Before running these functions with the code in the following cell we must delete the '.ipynb_checkpoint' files which might otherwise be considered as part of the dataset and interfere with training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laA_vd7A02hn"
      },
      "source": [
        "rm -rf `find -type d -name .ipynb_checkpoints`"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNV13MzS1-2M"
      },
      "source": [
        "**Step 6:** Run the function above with the desired parameters\n",
        "\n",
        "**As aforementioned, before running this, ensure that you have deleted the README.md file in the audio_data/background_noise directory.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQKXmoGxjKJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf2db6d-f715-4d44-ab3c-c461bb5e85ec"
      },
      "source": [
        "JSON_PATH = DATASET_ROOT_DIR + 'data.json'\n",
        "PROCESSING_METHOD = 'fft'\n",
        "SAMPLE_RATE = 16000\n",
        "EXPECTED_DURATION = 1 # in seconds\n",
        "WINDOW_SIZE_SAMPLES = 512\n",
        "WINDOW_STRIDE_SAMPLES = 320\n",
        "MFCC_COEFF_NUMBER = 13\n",
        "\n",
        "\n",
        "preprocess_entire_dataset(dataset_path = DATASET_ROOT_DIR, \n",
        "                   json_path = JSON_PATH, \n",
        "                   processing_method = PROCESSING_METHOD,\n",
        "                   sample_rate = SAMPLE_RATE, \n",
        "                   expected_duration = EXPECTED_DURATION, \n",
        "                   window_size = WINDOW_SIZE_SAMPLES, \n",
        "                   window_stride = WINDOW_STRIDE_SAMPLES, \n",
        "                   num_mfcc = MFCC_COEFF_NUMBER)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing _background_noise_\n",
            "Processing on\n",
            "Processing follow\n",
            "Processing left\n",
            "Processing bed\n",
            "Processing stop\n",
            "Processing backward\n",
            "Processing five\n",
            "Processing six\n",
            "Processing happy\n",
            "Processing go\n",
            "Processing visual\n",
            "Processing nine\n",
            "Processing wow\n",
            "Processing marvin\n",
            "Processing four\n",
            "Processing learn\n",
            "Processing tree\n",
            "Processing yes\n",
            "Processing house\n",
            "Processing eight\n",
            "Processing sheila\n",
            "Processing down\n",
            "Processing two\n",
            "Processing bird\n",
            "Processing three\n",
            "Processing off\n",
            "Processing zero\n",
            "Processing one\n",
            "Processing forward\n",
            "Processing dog\n",
            "Processing no\n",
            "Processing right\n",
            "Processing cat\n",
            "Processing seven\n",
            "Processing up\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nio7zr1n-f17"
      },
      "source": [
        "### 3) Build and evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz9DRkNBuhTF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25ccf189-5759-41d9-ff38-542fdc256c93"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "def load_data(data_path):\n",
        "    \"\"\"Loads training dataset from json file.\n",
        "        :param data_path (str): Path to json file containing data\n",
        "        :return X (ndarray): Inputs\n",
        "        :return y (ndarray): Targets\n",
        "    \"\"\"\n",
        "\n",
        "    print('loading data...')\n",
        "\n",
        "    with open(data_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    X = np.array(data['features'])\n",
        "    y = np.array(data['labels'])\n",
        "    return X, y\n",
        "\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
        "        :param history: Training history of model\n",
        "        :return:\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def prepare_datasets(test_size, validation_size):\n",
        "    \"\"\"Loads data and splits it into train, validation and test sets.\n",
        "    :param test_size (float): Value in [0, 1] indicating percentage of data set to allocate to test split\n",
        "    :param validation_size (float): Value in [0, 1] indicating percentage of train set to allocate to validation split\n",
        "    :return X_train (ndarray): Input training set\n",
        "    :return X_validation (ndarray): Input validation set\n",
        "    :return X_test (ndarray): Input test set\n",
        "    :return y_train (ndarray): Target training set\n",
        "    :return y_validation (ndarray): Target validation set\n",
        "    :return y_test (ndarray): Target test set\n",
        "    \"\"\"\n",
        "\n",
        "    print('preparing dataset...')\n",
        "\n",
        "    # load data\n",
        "    X, y = load_data(JSON_PATH)\n",
        "\n",
        "    # create train, validation and test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "    print(X_train.shape)\n",
        "    # add an axis to input sets\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_validation = X_validation[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n",
        "\n",
        "\n",
        "\n",
        "def build_model(input_shape):\n",
        "    \"\"\"Generates CNN model\n",
        "    :param input_shape (tuple): Shape of input set\n",
        "    :return model: CNN model\n",
        "    \"\"\"\n",
        "\n",
        "    # build network topology\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # 1st conv layer\n",
        "    model.add(keras.layers.Conv2D(16, (6, 6), activation='relu', input_shape=input_shape, padding='same'))\n",
        "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # 2nd conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # flatten output and feed it into dense layer\n",
        "    # model.add(keras.layers.Flatten())\n",
        "    # model.add(keras.layers.Dense(10, activation='relu'))\n",
        "    # model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "    # output layer\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(37, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def predict(model, X, y):\n",
        "    \"\"\"Predict a single sample using the trained model\n",
        "    :param model: Trained classifier\n",
        "    :param X: Input data\n",
        "    :param y (int): Target\n",
        "    \"\"\"\n",
        "\n",
        "    # add a dimension to input data for sample - model.predict() expects a 4d array in this case\n",
        "    X = X[np.newaxis, ...] # array shape (1, 130, 13, 1)\n",
        "\n",
        "    # perform prediction\n",
        "    prediction = model.predict(X)\n",
        "\n",
        "    # get index with max value\n",
        "    predicted_index = np.argmax(prediction, axis=1)\n",
        "\n",
        "    print(\"Target: {}, Predicted label: {}\".format(y, predicted_index))\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # get train, validation, test splits\n",
        "    X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)\n",
        "\n",
        "    # create network\n",
        "    print('X_train.shape: {}'.format(X_train.shape))\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "    model = build_model(input_shape)\n",
        "\n",
        "    # compile model\n",
        "    optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimiser,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=20)\n",
        "\n",
        "    # plot accuracy/error for training and validation\n",
        "    plot_history(history)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preparing dataset...\n",
            "loading data...\n",
            "(63500, 1, 400)\n",
            "X_train.shape: (63500, 1, 400, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 1, 400, 16)        592       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 1, 200, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1, 200, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 1, 200, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 1, 100, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1, 100, 32)        128       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 37)                118437    \n",
            "=================================================================\n",
            "Total params: 123,861\n",
            "Trainable params: 123,765\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1985/1985 [==============================] - 68s 34ms/step - loss: 2.8545 - accuracy: 0.2205 - val_loss: 2.2942 - val_accuracy: 0.3405\n",
            "Epoch 2/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 2.2061 - accuracy: 0.3629 - val_loss: 2.1483 - val_accuracy: 0.3808\n",
            "Epoch 3/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 2.0758 - accuracy: 0.4042 - val_loss: 2.0571 - val_accuracy: 0.4064\n",
            "Epoch 4/20\n",
            "1985/1985 [==============================] - 68s 34ms/step - loss: 1.9831 - accuracy: 0.4252 - val_loss: 2.0167 - val_accuracy: 0.4159\n",
            "Epoch 5/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.9234 - accuracy: 0.4433 - val_loss: 1.9941 - val_accuracy: 0.4237\n",
            "Epoch 6/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.8895 - accuracy: 0.4518 - val_loss: 1.9382 - val_accuracy: 0.4385\n",
            "Epoch 7/20\n",
            "1985/1985 [==============================] - 68s 34ms/step - loss: 1.8284 - accuracy: 0.4641 - val_loss: 1.9938 - val_accuracy: 0.4169\n",
            "Epoch 8/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.8034 - accuracy: 0.4759 - val_loss: 1.9178 - val_accuracy: 0.4403\n",
            "Epoch 9/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.7720 - accuracy: 0.4849 - val_loss: 1.9272 - val_accuracy: 0.4358\n",
            "Epoch 10/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.7488 - accuracy: 0.4923 - val_loss: 1.8922 - val_accuracy: 0.4516\n",
            "Epoch 11/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.7231 - accuracy: 0.5006 - val_loss: 1.8706 - val_accuracy: 0.4560\n",
            "Epoch 12/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.6868 - accuracy: 0.5101 - val_loss: 1.8759 - val_accuracy: 0.4557\n",
            "Epoch 13/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.6580 - accuracy: 0.5169 - val_loss: 1.8711 - val_accuracy: 0.4543\n",
            "Epoch 14/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.6449 - accuracy: 0.5186 - val_loss: 1.8766 - val_accuracy: 0.4543\n",
            "Epoch 15/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.6290 - accuracy: 0.5248 - val_loss: 1.8314 - val_accuracy: 0.4691\n",
            "Epoch 16/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.6069 - accuracy: 0.5285 - val_loss: 1.8614 - val_accuracy: 0.4573\n",
            "Epoch 17/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.5809 - accuracy: 0.5356 - val_loss: 1.8558 - val_accuracy: 0.4609\n",
            "Epoch 18/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.5644 - accuracy: 0.5435 - val_loss: 1.8269 - val_accuracy: 0.4705\n",
            "Epoch 19/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.5597 - accuracy: 0.5439 - val_loss: 1.8385 - val_accuracy: 0.4664\n",
            "Epoch 20/20\n",
            "1985/1985 [==============================] - 67s 34ms/step - loss: 1.5351 - accuracy: 0.5494 - val_loss: 1.8560 - val_accuracy: 0.4638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UzQyblHauQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3ab69f-9ea5-470b-9b16-a15e64ee3c46"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "# pick a sample to predict from the test set\n",
        "X_to_predict = X_test[100]\n",
        "y_to_predict = y_test[100]\n",
        "\n",
        "# predict sample\n",
        "predict(model, X_to_predict, y_to_predict)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "827/827 - 8s - loss: 1.8415 - accuracy: 0.4749\n",
            "\n",
            "Test accuracy: 0.4749234616756439\n",
            "Target: 26, Predicted label: [26]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym2VPa_GqUUG"
      },
      "source": [
        "### 4) Save model and convert to desired formats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG0mAr41po2x"
      },
      "source": [
        "Save keras model as an .h5 file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Ay09Hr1CzD"
      },
      "source": [
        "model.save(\"all_words_fft.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM4WBSa7p1-I"
      },
      "source": [
        "Convert the model to a quantized tflite model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEQYCXLUbbSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac7a597-353f-4daf-f93a-48f30629a846"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "def representative_dataset_generator():\n",
        "  for value in X_test:\n",
        "    yield [np.array(value, dtype = np.float32, ndmin=4)]\n",
        "\n",
        "converter.representative_dataset = representative_dataset_generator\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"all_words_fft.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"all_words_fft.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpiw9ksaq5/assets\n",
            "Model is 420788 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt2aD7aUoEuS"
      },
      "source": [
        "Convert model from tflite file to byte array for deployment on Arduino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1OgjXKln-b3"
      },
      "source": [
        "!apt-get -qq install xxd\n",
        "!xxd -i all_words_fft.tflite > all_words_fft.cc\n",
        "!cat all_words_fft.cc"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}