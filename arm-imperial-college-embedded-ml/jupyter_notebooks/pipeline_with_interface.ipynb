{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "with_interface.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDKVJZ0SnY8z"
      },
      "source": [
        "# Audio classifier pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "wuPIoMU9rUqO"
      },
      "source": [
        "#@title ## **Input Parameters**\n",
        "\n",
        "#@markdown #### _**This section contains essential parameters regarding the functionality of this platform.**_\n",
        "#@markdown #### _**Please complete the following fields and then go to the 'Runtime' tab on the top of the page and click 'Run all'.**_\n",
        "\n",
        "#@markdown _\n",
        "\n",
        "#@markdown ####**1. Dataset selection:**\n",
        "#@markdown Copy and paste the URL of the dataset to be used. To change between datasets change the url to one which downloads a .tar file.\n",
        "\n",
        "#@markdown *Default:* Speech Commands\n",
        "\n",
        "\n",
        "dataset_url = 'http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz' #@param {type: 'string'}\n",
        "\n",
        "#@markdown _\n",
        "\n",
        "#@markdown ####**2. Processing method:**\n",
        "\n",
        "#@markdown Choose between processing methods (None/FFT/STFT/MFCC) by clicking on the dropdown menu arrow.\n",
        "\n",
        "#@markdown *Default:* None\n",
        "\n",
        "processing_method = 'MFCC' #@param ['None', 'FFT', 'STFT', 'MFCC'] {allow-input: true}\n",
        "\n",
        "#@markdown _\n",
        "\n",
        "#@markdown ####**3. Processing parameters:**\n",
        "\n",
        "#@markdown Different parameters must be set depending on the processing method used. This is depicted in the following table. \n",
        "\n",
        "#@markdown **!!!** If a parameter does not say 'YES' for your processing method of choice, please leave it at its default value. **!!!**\n",
        "\n",
        "#@markdown |||/| sample_rate |/| expected_duration |/| window_size |/| window_stride |/| mfcc_coeff_number\n",
        "#@markdown ------------ ||| ------------- || ------------- || ------------- || ------------- || -------------\n",
        "#@markdown None ||/| YES |/| YES |/|  |/|  |/|\n",
        "#@markdown FFT  ||/| YES |/| YES |/|  |/|  |/|\n",
        "#@markdown STFT ||/| YES |/| YES |/| YES |/| YES |/|\n",
        "#@markdown MFCC ||/| YES |/| YES |/| YES |/| YES |/| YES\n",
        "\n",
        "#@markdown _\n",
        "\n",
        "#@markdown Only two values are allowed for the sampling rate so please choose from the dropdown menu. \n",
        "#@markdown Also note that the expected duration of the audio track is in seconds.\n",
        "\n",
        "sample_rate = \"16000\" #@param [16000, 44100] {allow-input: true}\n",
        "expected_duration = 1.024 #@param {type: 'number'}\n",
        "\n",
        "#@markdown _\n",
        "\n",
        "#@markdown Only powers of two are allowed as window size for the STFT and MFCC algorithms so please choose from the dropdown menu. Note that this constraint is not valid for the window stride.\n",
        "window_size = \"512\" #@param [256, 512, 1024, 2048, 4096, 8192] {allow-input: true}\n",
        "window_stride =  320 #@param {type: 'number'}\n",
        "mfcc_coeff_number = 13 #@param {type: 'number'}\n",
        "\n",
        "#@markdown _\n",
        "\n",
        "#@markdown ####**4. Neural Network parameters:**\n",
        "\n",
        "#@markdown Choose the number of classes between which you're classifying.\n",
        "\n",
        "num_of_classes = 4 #@param {type: 'number'}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v3fpsWlufbb",
        "outputId": "298a10a2-75a2-4176-8a36-1e32d97b3b0b"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "if tf.__version__ == '2.2.0':\n",
        "  print(\"Correct tensorflow version: {}\".format(tf.__version__))\n",
        "else:\n",
        "  print(\"Wrong tensorflow version! Should be 2.2.0 but is {}\".format(tf.__version__))\n",
        "  !pip uninstall tensorflow -y\n",
        "  !pip install  tensorflow==2.2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct tensorflow version: 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBu_MVltrflI"
      },
      "source": [
        "DATASET_URL = dataset_url\n",
        "DATASET_ROOT_DIR = 'audio_data/'\n",
        "JSON_PATH = 'data.json'\n",
        "\n",
        "PROCESSING_METHOD = lower(processing_method)\n",
        "\n",
        "SAMPLE_RATE = int(sample_rate)\n",
        "EXPECTED_DURATION = expected_duration\n",
        "WINDOW_SIZE_SAMPLES = int(window_size)\n",
        "WINDOW_STRIDE_SAMPLES = window_stride\n",
        "MFCC_COEFF_NUMBER = mfcc_coeff_number\n",
        "\n",
        "NUM_OF_CLASSES = num_of_classes"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhjmJcqIe4Ku"
      },
      "source": [
        "### 1) Download and untar dataset directly to colab:\n",
        "\n",
        "To change between datasets change the url to one which downloads a .tar file.\n",
        "\n",
        "**Other important notes:**\n",
        "\n",
        "**1.** If the audio_data folder already exists in your colab session running the following cell will give an error. That is not a problem, run it anyway.\n",
        "\n",
        "**2.** To load the audio samples we use the librosa library. Its load function supports a large range of input formats such as WAV, MP3, FLAC, OGG and many others. For the full list of available input formats please refer to the documentation at https://librosa.org/doc/main/generated/librosa.load.html. An important point is that the library can't load README files, which can often be found in datasets in the form of .md and .txt files. Not deleting such files will cause the library to fail when processing the dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hROJGZ_rWPGa"
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "os.mkdir(DATASET_ROOT_DIR)\n",
        "url = DATASET_URL\n",
        "target_path = 'audio_data/dataset.tar.gz'\n",
        "\n",
        "response = requests.get(url, stream=True)\n",
        "if response.status_code == 200:\n",
        "    with open(target_path, 'wb') as f:\n",
        "        f.write(response.raw.read())\n",
        "\n",
        "tar = tarfile.open(target_path, \"r:gz\")\n",
        "tar.extractall(path='audio_data/')\n",
        "tar.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_mTATcwlAle"
      },
      "source": [
        "### 2) Preprocess dataset:\n",
        "\n",
        "We iterate through the entire dataset, process every audio track using a processing method (either FFT, STFT, or MFCC), and store all of them in a JSON file. Currently, the user is able to control the processing method, expected duration of the audio tracks, the sample rate, as well as other values related to the processing methods.\n",
        "\n",
        "Potentially, the user might also be able (in the future) to automatically go through all processing methods and use the one which optimizes the current model accuracy.\n",
        "\n",
        "The process explained above can be completed through the following steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-hzEODswh24"
      },
      "source": [
        "**Step 1:** Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q868TWmywSTW"
      },
      "source": [
        "import os\n",
        "import librosa\n",
        "import math\n",
        "import json\n",
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jsjd9sGwsbw"
      },
      "source": [
        "**Step 2:** Function to extend/cut tracks appropriately so that all contain the expected number of samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExNJOdGAwUS3"
      },
      "source": [
        "def make_track_correct_size(signal, expected_num_samples_per_track):\n",
        "\n",
        "    # print('Original track length: {}'.format(len(signal)))\n",
        "    # if track is shorter than expected, append it with zeros\n",
        "    if len(signal) < expected_num_samples_per_track:\n",
        "      num_zeros_to_pad = expected_num_samples_per_track - len(signal)\n",
        "      zeros = num_zeros_to_pad * [0.]\n",
        "      extended_signal = np.append(signal, zeros)\n",
        "      return extended_signal\n",
        "\n",
        "    # if track is longer than expected, truncate it\n",
        "    elif len(signal) > expected_num_samples_per_track:\n",
        "      return signal[:expected_num_samples_per_track]\n",
        "\n",
        "    # else return the original track \n",
        "    else:\n",
        "      return signal"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5KBOt9mw9o-"
      },
      "source": [
        "**Step 3:** Define function to process a single track using the specified method (FFT/STFT/MFCC) and return the data structure containing the result. This function will be called for all tracks within the dataset. Also note that we always return a 1D array by flattening the 2D arrays where necessary. We do this so that we can replicate the exact same preprocessing on Arduino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ndxpmhtwYhw"
      },
      "source": [
        "def audio_track_to_features(signal, processing_method, sample_rate, window_size, window_stride, num_mfcc):\n",
        "  if processing_method == 'none':\n",
        "    # if no processing method is selected we only averaged the signal every 32 samples\n",
        "    averaged = np.mean(signal.reshape(-1, 32), axis=1)\n",
        "    return averaged\n",
        "\n",
        "  elif processing_method == 'fft':\n",
        "    # perform Fast Fourier Transform (FFT)\n",
        "    fft = np.fft.fft(signal)\n",
        "\n",
        "    # calculate abs values on complex numbers to get magnitude\n",
        "    spectrum = np.abs(fft)\n",
        "\n",
        "    # the spectrum is symmetrical with respect to sample_rate / 2\n",
        "    # so take half of the spectrum and frequency arrays\n",
        "    # therefore len(half_spectrum) = sample_rate / 2\n",
        "    half_spectrum = spectrum[:int(len(spectrum)/2)]\n",
        "\n",
        "    # average every 16 samples to reduce size of array to 1 / 16 of its original size\n",
        "    # e.g. sample_rate = 16k, duration = 1.024s, reduce size from 8192 to 512 \n",
        "    averaged = np.mean(half_spectrum.reshape(-1, 16), axis=1)\n",
        "\n",
        "    # transform to range -128 to 127\n",
        "    averaged *= (255.0/averaged.max()) # 0-255\n",
        "    averaged -= 128\n",
        "\n",
        "    return averaged\n",
        "\n",
        "\n",
        "  elif processing_method == 'stft':\n",
        "    # perform Short Time Fourier Transform (STFT)\n",
        "    stft = librosa.stft(signal = signal, \n",
        "                        n_fft = window_size, \n",
        "                        hop_length = window_stride)\n",
        "\n",
        "    # calculate abs values on complex numbers to get magnitude\n",
        "    spectrogram = np.abs(stft)\n",
        "\n",
        "    # transpose and return the spectrogram matrix\n",
        "    transposed_spectrogram = spectrogram.transpose()\n",
        "    return transposed_spectrogram.flatten()\n",
        "\n",
        "\n",
        "  else: # mfcc\n",
        "    # perform Mel-Frequency Cepstral Coefficients (MFCC)\n",
        "    mfcc = librosa.feature.mfcc(signal, \n",
        "                                sr = sample_rate, \n",
        "                                n_fft = window_size, \n",
        "                                n_mfcc = num_mfcc,\n",
        "                                hop_length = window_stride)\n",
        "    # transpose and return the mfcc matrix\n",
        "    transposed_mfcc = mfcc.T\n",
        "    return transposed_mfcc.flatten()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcI71k9s1tg2"
      },
      "source": [
        "**Step 4:** Define function to process every audio track and create a JSON file with the entire processed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBwlSAsbfyKi"
      },
      "source": [
        "def preprocess_entire_dataset(dataset_path, json_path, processing_method, sample_rate, expected_duration, window_size, window_stride, num_mfcc):\n",
        "  # expected duration is in seconds\n",
        "  expected_num_samples_per_track = int(expected_duration * sample_rate)\n",
        "  \n",
        "  # dictionary to later be converted to final json file\n",
        "  data = {\n",
        "      'mapping' : [],\n",
        "      'features' : [],\n",
        "      'labels' : []\n",
        "  }\n",
        "\n",
        "  # we will iterate this for each of the visited sub-directorie in order to\n",
        "  # give a different label for each of them\n",
        "  visited_directory_index = 0\n",
        "\n",
        "  # iterate through all subfolders\n",
        "  for dirpath, dirnames, filenames in os.walk(dataset_path):\n",
        "\n",
        "    # # ensure we are not at the dataset root directory\n",
        "    # # (os.walk provides this directory as well)\n",
        "    # if dirpath is not DATASET_ROOT_DIR:\n",
        "    if dirpath == 'audio_data/yes' or dirpath == 'audio_data/no' or dirpath == 'audio_data/bed' or dirpath == 'audio_data/_background_noise_':\n",
        "\n",
        "      # obtain word labels\n",
        "      dirpath_components = dirpath.split('/') # audio_data/left => ['audio_data', 'left']\n",
        "      word_label = dirpath_components[-1]\n",
        "      data['mapping'].append(word_label)\n",
        "      print('Processing {}'.format(word_label))\n",
        "\n",
        "      # access and process files for current word\n",
        "      for f in filenames:\n",
        "\n",
        "        # load audio file\n",
        "        file_path = os.path.join(dirpath, f)\n",
        "        signal, sample_rate = librosa.load(file_path, sr=sample_rate)\n",
        "\n",
        "        # extend or cut signal to be equal to the expected size\n",
        "        signal_correct_size = make_track_correct_size(signal, expected_num_samples_per_track)\n",
        "\n",
        "        # obtain the features of the audio track using the function defined above\n",
        "        track_features = audio_track_to_features(signal = signal_correct_size, \n",
        "                                                processing_method = processing_method,\n",
        "                                                sample_rate = sample_rate, \n",
        "                                                window_size = window_size, \n",
        "                                                window_stride = window_stride, \n",
        "                                                num_mfcc = num_mfcc)\n",
        "\n",
        "        # append the audio track features to the features field of the dictionary\n",
        "        data['features'].append(track_features.tolist())\n",
        "\n",
        "        # append the current directory index as the label of this track\n",
        "        data['labels'].append(visited_directory_index)\n",
        "        # print('file_path: {}'.format(file_path))\n",
        "\n",
        "      # iterate the index before visiting the next directory\n",
        "      visited_directory_index = visited_directory_index + 1\n",
        "\n",
        "  print(data['mapping'])\n",
        "  print(set(data['labels']))\n",
        "  # create the json file from the dictionary\n",
        "  with open(json_path, 'w') as fp:\n",
        "    json.dump(data, fp, indent=4)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kApAU17Yk2rS"
      },
      "source": [
        "**Step 5:** Before running these functions with the code in the following cell we must delete the '.ipynb_checkpoint' files which might otherwise be considered as part of the dataset and interfere with training the model. We also delete the README.md file in the audio_data/background_noise directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laA_vd7A02hn"
      },
      "source": [
        "rm -rf `find -type d -name .ipynb_checkpoints`"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJaCkd1Ny2BD"
      },
      "source": [
        "!rm audio_data/_background_noise_/README.md"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNV13MzS1-2M"
      },
      "source": [
        "**Step 6:** Run the preprocessing function above with the desired parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQKXmoGxjKJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c517369-4e01-4d0c-b9c0-e6f01b595647"
      },
      "source": [
        "preprocess_entire_dataset(dataset_path = DATASET_ROOT_DIR, \n",
        "                   json_path = JSON_PATH, \n",
        "                   processing_method = PROCESSING_METHOD,\n",
        "                   sample_rate = SAMPLE_RATE, \n",
        "                   expected_duration = EXPECTED_DURATION, \n",
        "                   window_size = WINDOW_SIZE_SAMPLES, \n",
        "                   window_stride = WINDOW_STRIDE_SAMPLES, \n",
        "                   num_mfcc = MFCC_COEFF_NUMBER)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing _background_noise_\n",
            "Processing yes\n",
            "Processing no\n",
            "Processing bed\n",
            "['_background_noise_', 'yes', 'no', 'bed']\n",
            "{0, 1, 2, 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nio7zr1n-f17"
      },
      "source": [
        "### 3) Build and evaluate model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoJGGu3MraXK"
      },
      "source": [
        "**Step 1:** Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSHmrMl1rjFd"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Reshape, Activation, BatchNormalization, Conv2D, MaxPooling2D, Flatten\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-VELpQkrmk9"
      },
      "source": [
        "**Step 2:** Define functions to load and prepare the dataset for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYFesrHkrvVX"
      },
      "source": [
        "def load_data(data_path):\n",
        "    \"\"\"Loads training dataset from json file.\n",
        "        :param data_path (str): Path to json file containing data\n",
        "        :return X (ndarray): Inputs\n",
        "        :return y (ndarray): Targets\n",
        "    \"\"\"\n",
        "\n",
        "    print('Loading dataset')\n",
        "\n",
        "    with open(data_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    X = np.array(data['features'])\n",
        "    y = np.array(data['labels'])\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def prepare_datasets(test_size, validation_size):\n",
        "    \"\"\"Loads data and splits it into train, validation and test sets.\n",
        "    :param test_size (float): Value in [0, 1] indicating percentage of data set to allocate to test split\n",
        "    :param validation_size (float): Value in [0, 1] indicating percentage of train set to allocate to validation split\n",
        "    :return X_train (ndarray): Input training set\n",
        "    :return X_validation (ndarray): Input validation set\n",
        "    :return X_test (ndarray): Input test set\n",
        "    :return y_train (ndarray): Target training set\n",
        "    :return y_validation (ndarray): Target validation set\n",
        "    :return y_test (ndarray): Target test set\n",
        "    \"\"\"\n",
        "\n",
        "    print('Splitting dataset into training, validation, and test splits')\n",
        "\n",
        "    # load data\n",
        "    X, y = load_data(JSON_PATH)\n",
        "\n",
        "    # create train, validation and test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "\n",
        "    # add an axis to input sets for conv networks to fit conv2D shape specs\n",
        "    # currently not needed since we reshape everything anyway\n",
        "    # X_train = X_train[..., np.newaxis]\n",
        "    # X_validation = X_validation[..., np.newaxis]\n",
        "    # X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    return X_train, X_validation, X_test, y_train, y_validation, y_test"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzYXN1Qr5UQ"
      },
      "source": [
        "**Step 3:** Define seperate functions for building a dense and a convolutional model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpkZZWWWyOPR"
      },
      "source": [
        "def build_conv_model(input_shape, reshape_shape, number_of_classes):\n",
        "    \"\"\"Generates CNN model\n",
        "    :param input_shape (tuple): Shape of input set\n",
        "    :return model: CNN model\n",
        "    \"\"\"\n",
        "\n",
        "    # build network topology\n",
        "    model = Sequential()\n",
        "\n",
        "    # reshape input from 1D to 2D\n",
        "    model.add(Reshape(reshape_shape, input_shape=input_shape))\n",
        "\n",
        "    # 1st conv layer\n",
        "    model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # 2nd conv layer\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # flatten output and feed it into dense layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # output layer\n",
        "    model.add(Dense(number_of_classes, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4dmf8Our4xf"
      },
      "source": [
        "def build_dense_model(input_shape, number_of_classes):\n",
        "    \"\"\"Generates CNN model\n",
        "    :param input_shape (tuple): Shape of input set\n",
        "    :return model: CNN model\n",
        "    \"\"\"\n",
        "\n",
        "    # build network topology\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(16, activation='relu', input_shape=input_shape))\n",
        "    # model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "\n",
        "    # model.add(Dense(256, activation='relu'))\n",
        "    # # model.add(Dropout(0.3))\n",
        "\n",
        "    # model.add(Dense(512, activation='relu'))\n",
        "    # # model.add(Dropout(0.3))\n",
        "\n",
        "    # model.add(Dense(256, activation='relu'))\n",
        "\n",
        "    # model.add(Dense(128, activation='relu'))\n",
        "    # # model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "\n",
        "    # output layer\n",
        "    model.add(Dense(number_of_classes, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1zV2CG0sAvQ"
      },
      "source": [
        "**Step 4:** Define function to plot the training history of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz9DRkNBuhTF"
      },
      "source": [
        "def plot_history(history):\n",
        "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
        "        :param history: Training history of model\n",
        "        :return:\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uhitZN4t_8y"
      },
      "source": [
        "**Step 5:** Run all of the above functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKb7aMsg6cdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be680520-3c9d-425b-8cdd-bd2bd2dd8eb0"
      },
      "source": [
        "# get train, validation, test splits\n",
        "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)\n",
        "print('Finished preparing training, validation, and test data')\n",
        "print('X_train.shape: {}'.format(X_train.shape))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Splitting dataset into training, validation, and test splits\n",
            "Loading dataset\n",
            "Finished preparing training, validation, and test data\n",
            "X_train.shape: (6002, 676)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvHUkZjX41S9"
      },
      "source": [
        "**Step 6:** Since when preprocessing the entire dataset we flattened all 2D arrays to 1D arrays, we calculate the original 2D dimentions in order to Reshape in the first layer of our Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Koahh8P0JwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9206a29-90da-4527-ec4b-113ea15897fc"
      },
      "source": [
        "NUM_OF_SAMPLES = SAMPLE_RATE * EXPECTED_DURATION\n",
        "# none\n",
        "AVERAGED_SIGNAL_ARRAY_SIZE = int(NUM_OF_SAMPLES / 32) # averaging every 32 samples\n",
        "# FFT\n",
        "FFT_ARRAY_SIZE = int((NUM_OF_SAMPLES) / (2 * 16))  # 2 comes from half spectrum, 16 from averaging every 16 samples\n",
        "# STFT, MFCC\n",
        "NUM_OF_WINDOW_POSITIONS = math.ceil(NUM_OF_SAMPLES / WINDOW_STRIDE_SAMPLES)\n",
        "NUM_OF_STFT_FREQUENCIES = int(1 + WINDOW_SIZE_SAMPLES / 2)\n",
        "\n",
        "\n",
        "if PROCESSING_METHOD == 'none':\n",
        "  RESHAPE_SHAPE = (1, AVERAGED_SIGNAL_ARRAY_SIZE, 1)\n",
        "elif PROCESSING_METHOD == 'fft':\n",
        "  RESHAPE_SHAPE = (1, FFT_ARRAY_SIZE, 1)\n",
        "elif PROCESSING_METHOD == 'stft':\n",
        "  RESHAPE_SHAPE = (NUM_OF_WINDOW_POSITIONS, NUM_OF_STFT_FREQUENCIES, 1)\n",
        "else: # mfcc\n",
        "  RESHAPE_SHAPE = (NUM_OF_WINDOW_POSITIONS, MFCC_COEFF_NUMBER, 1)\n",
        "\n",
        "print('processing method: {}, \\nreshape shape: {}'.format(PROCESSING_METHOD, RESHAPE_SHAPE))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing method: MFCC, \n",
            "reshape shape: (52, 13, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4xgyIift_ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c83a0673-3a86-4fcb-a388-1d2f7d9127cb"
      },
      "source": [
        "network_is_convolutional = True\n",
        "\n",
        "# for convolutional model\n",
        "if network_is_convolutional:\n",
        "  input_shape = (X_train.shape[1],)\n",
        "  print(\"input_shape = {}\".format(input_shape))\n",
        "  model = build_conv_model(input_shape, RESHAPE_SHAPE, NUM_OF_CLASSES)\n",
        "# for dense model\n",
        "else:\n",
        "  input_shape = (X_train.shape[1],)\n",
        "  print(\"input_shape = {}\".format(input_shape))\n",
        "  model = build_dense_model(input_shape, NUM_OF_CLASSES)\n",
        "\n",
        "\n",
        "# compile model\n",
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimiser,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# train model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=20)\n",
        "\n",
        "# plot accuracy/error for training and validation\n",
        "plot_history(history)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape = (676,)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 52, 13, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 52, 13, 8)         80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 26, 7, 8)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 26, 7, 8)          32        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 26, 7, 16)         1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 4, 16)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 13, 4, 16)         64        \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 4, 32)         4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 2, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 2, 32)          128       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 448)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                4490      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 44        \n",
            "=================================================================\n",
            "Total params: 10,646\n",
            "Trainable params: 10,534\n",
            "Non-trainable params: 112\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 1.1907 - accuracy: 0.4562 - val_loss: 1.0732 - val_accuracy: 0.6376\n",
            "Epoch 2/20\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.9092 - accuracy: 0.6086 - val_loss: 0.7710 - val_accuracy: 0.7375\n",
            "Epoch 3/20\n",
            "188/188 [==============================] - 5s 28ms/step - loss: 0.7639 - accuracy: 0.6844 - val_loss: 0.6225 - val_accuracy: 0.8008\n",
            "Epoch 4/20\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.6740 - accuracy: 0.7329 - val_loss: 0.5114 - val_accuracy: 0.8328\n",
            "Epoch 5/20\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.6007 - accuracy: 0.7662 - val_loss: 0.4493 - val_accuracy: 0.8588\n",
            "Epoch 6/20\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.5521 - accuracy: 0.7857 - val_loss: 0.4043 - val_accuracy: 0.8834\n",
            "Epoch 7/20\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.5150 - accuracy: 0.7966 - val_loss: 0.3686 - val_accuracy: 0.8921\n",
            "Epoch 8/20\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.4774 - accuracy: 0.8129 - val_loss: 0.3389 - val_accuracy: 0.8967\n",
            "Epoch 9/20\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.4401 - accuracy: 0.8257 - val_loss: 0.3077 - val_accuracy: 0.9074\n",
            "Epoch 10/20\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.4100 - accuracy: 0.8369 - val_loss: 0.2868 - val_accuracy: 0.9101\n",
            "Epoch 11/20\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.3831 - accuracy: 0.8509 - val_loss: 0.2916 - val_accuracy: 0.9067\n",
            "Epoch 12/20\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.3707 - accuracy: 0.8595 - val_loss: 0.2742 - val_accuracy: 0.9121\n",
            "Epoch 13/20\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.3395 - accuracy: 0.8712 - val_loss: 0.2483 - val_accuracy: 0.9174\n",
            "Epoch 14/20\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.3279 - accuracy: 0.8804 - val_loss: 0.2602 - val_accuracy: 0.9067\n",
            "Epoch 15/20\n",
            "188/188 [==============================] - 6s 32ms/step - loss: 0.3101 - accuracy: 0.8809 - val_loss: 0.2352 - val_accuracy: 0.9194\n",
            "Epoch 16/20\n",
            "188/188 [==============================] - 6s 35ms/step - loss: 0.3082 - accuracy: 0.8857 - val_loss: 0.2182 - val_accuracy: 0.9267\n",
            "Epoch 17/20\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2793 - accuracy: 0.8990 - val_loss: 0.2159 - val_accuracy: 0.9234\n",
            "Epoch 18/20\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.2710 - accuracy: 0.8985 - val_loss: 0.2028 - val_accuracy: 0.9314\n",
            "Epoch 19/20\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.2574 - accuracy: 0.9029 - val_loss: 0.1931 - val_accuracy: 0.9320\n",
            "Epoch 20/20\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.2470 - accuracy: 0.9080 - val_loss: 0.1983 - val_accuracy: 0.9327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcG0tIUzV-UR"
      },
      "source": [
        "**Step 7:** Evaluate the model's test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLWEe0hsWCni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2608d1b3-019f-426f-82c6-39f0a79233b4"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 - 1s - loss: 0.2134 - accuracy: 0.9257\n",
            "\n",
            "Test accuracy: 0.9256594777107239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym2VPa_GqUUG"
      },
      "source": [
        "### 4) Save model and convert to desired formats:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG0mAr41po2x"
      },
      "source": [
        "Save keras model as an .h5 file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Ay09Hr1CzD"
      },
      "source": [
        "model.save('generated_model.h5')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM4WBSa7p1-I"
      },
      "source": [
        "Convert the model to a (currently not quantized due to commented out lines) tflite model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEQYCXLUbbSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c778476b-4e76-4959-a535-f7b465d95d41"
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# def representative_dataset_generator():\n",
        "#   for value in X_test:\n",
        "#     yield [np.array(value, dtype = np.float32, ndmin=4)]\n",
        "\n",
        "# converter.representative_dataset = representative_dataset_generator\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open('generated_model.tflite', \"wb\").write(tflite_model)\n",
        "\n",
        "import os\n",
        "basic_model_size = os.path.getsize('generated_model.tflite')\n",
        "print(\"Model is %d bytes\" % basic_model_size)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model is 47324 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt2aD7aUoEuS"
      },
      "source": [
        "Convert model from tflite file to byte array for deployment on Arduino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1OgjXKln-b3"
      },
      "source": [
        "!apt-get -qq install xxd\n",
        "!xxd -i generated_model.tflite > generated_model.cc"
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}